Keep (Public)	Withhold (Private)	Replace with Stub (Reason)
Environment Interface – The abstract class P2PMarketEnv (in api.environment) with method signatures.	Full market environment implementation – The detailed simulation of the continuous double auction, prosumer/consumer interactions, storage dynamics, and fairness integration.	Replaced by ToyMarketEnv in demo_env.py, which uses random behavior. Reason: to illustrate the interface without revealing core simulation logic (research IP).
Agent Policy Interface – Abstract AgentPolicy class defining select_action.	Learning Agents and Neural Network Implementation – The PPO actor-critic model (ActorCritic class) and per-agent learning logic.	Replaced by RandomPolicy (random action generator) in the demo. Reason: core RL training code is proprietary and not included; a random policy is used to show how an agent might interact.
Configuration Schema – YAML config file structure (keys like n_prosumers, n_consumers, etc.) reflecting the paper’s terminology.	Full experiment configs & hyperparameters – Actual training parameters (e.g. 10,000 episodes, reward weights, curriculum schedule) and any real-world dataset paths.	Provided a simplified configs/demo.yaml with toy values (e.g. 1 day, small scale). Reason: to demonstrate format without exposing tuned hyperparameters or sensitive data.
Logging Format – The CSV log includes columns for fairness metrics (FTG, FBS, FPP) and steps.	Real training/evaluation logs – Detailed logs of rewards, losses, and performance from the private experiments; any analysis scripts for plotting results.	The demo generates a tiny demo_run.csv with placeholder metrics. Reason: to show output structure without revealing actual results or enabling result reproduction.
Documentation & Metadata – README, API docs, and citation info describing FairMarket-RL’s concepts.	Detailed methodology implementation – The exact code that computes fairness scores (LLM calls or formulas), reward shaping integration, and complex logic described in the paper.	Referenced conceptually in docs, but not present in code. NotImplemented stubs (in placeholders/) will raise errors if accessed. Reason: these are core research contributions and possibly use external APIs (e.g. OpenAI) – omitted to protect IP and because they require proprietary resources.
Security/Secrets – No secrets included; public repo contains no API keys or credentials.	Secrets & Credentials – e.g. the OpenAI API key and calls for LLM critic, or any internal endpoints.	Removed entirely. Reason: protect security – the code was sanitized to eliminate any secret tokens.
